{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Question-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Question 1</a></div><div class=\"lev1\"><a href=\"#Question-4\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Question 4</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "(25pt + 10pt) In this question, we use the file {\\tt brader.csv} which contains data from Brader, Valentino and Suhay (2008). The file includes the following variables for $n=265$ observations:\n",
    "\n",
    "* the outcome of interest -- a four-point scale in response to ``Do you think the number of immigrants from foreign countries should be increased or decreased?''\n",
    "* tone of the story treatment (positive or negative)\n",
    "* ethnicity of the featured immigrant treatment (Mexican or Russian)\n",
    "* respondents' age\n",
    "* respondents' income\n",
    "\\end{itemize}\n",
    "\n",
    "Consider the following ordered logit model for an ordered outcome variable with four levels:\n",
    "        $$ \\Pr(Y_i \\leq j \\mid X_i) \\ = \\ \\frac{\\exp(\\psi_j - X_i^\\top\\beta)}\n",
    "            {1 + \\exp(\\psi_j - X_i^\\top\\beta)} $$\n",
    "for $j = 1,2,3,4$ and $i = 1,...,n$ where $\\psi_4=\\infty$ and $X_i = [{\\tt tone}_i \\ {\\tt eth}_i \\ {\\tt ppage}_i \\ {\\tt ppincimp}_i]^\\top$ (i.e. no intercept).\n",
    "\n",
    "a) (5pt) Write down the likelihood function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "l = \n",
    "\\prod_{i=1}^n \n",
    "\\frac{\\exp(\\psi_{Y_i} - X_i^\\top\\beta)}\n",
    "     {1 + \\exp(\\psi_{Y_i} - X_i^\\top\\beta)} -\n",
    "\\frac{\\exp(\\psi_{Y_i-1} - X_i^\\top\\beta)}\n",
    "     {1 + \\exp(\\psi_{Y_i-1} - X_i^\\top\\beta)} =\n",
    "$$\n",
    "\n",
    "To simplify, from here on $\\phi$ will be the inverse link function and $\\phi'$ its derivative. Now we can write this in a more Matricial form as:\n",
    "\n",
    "$$\n",
    "\\prod_{i=1}^n \\sum_{j=1}^4\n",
    "\\tilde M_{i,j}\n",
    "\\phi\\left(\\psi_{j} - \\sum_{k=1}^m X_{ik}\\beta_k\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\tilde M = MK =  M \n",
    "\\begin{pmatrix}\n",
    "  1 &  0 &  0 &  0\\\\\n",
    " -1 &  1 &  0 &  0\\\\\n",
    "  0 & -1 &  1 &  0\\\\\n",
    "  0 &  0 & -1 &  1\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "And $M$ is the OneHot matrix for the $Y_i$, i.e. a matrix that has $n$ rows, and each row is the row vector with zeros everywhere but at the position $j$, where the the observed $Y$ is $Y_j$.  \n",
    "\n",
    "In practice, however, we are interested in the log-likelihood, which is:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^n \\log \\sum_{j=1}^4\n",
    "\\tilde M_{i,j}\n",
    "\\phi\\left(\\psi_{j} - \\sum_{k=1}^m X_{ik}\\beta_k\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we do it in R:\n",
    "\n",
    "# Function log_likelihood\n",
    "#\n",
    "# @ Param: Y the observed Y values (a n-vector in our case)\n",
    "# @ Param: X the observed X values (a n by m vector in our case )\n",
    "# @ Param: beta, the beta vector (m-vector in our case)\n",
    "# @ Param: psi, the four phi values we talk about above\n",
    "#          IMPORTANT: IT assumes that the last parameter (~infinity)\n",
    "#                     IS passed as a part of psi!!!\n",
    "#\n",
    "# @ Returns: The equation above\n",
    "\n",
    "log_likelihood = function(Y = 0,X,beta,psi, M = 0){\n",
    "    m = length(psi)+1\n",
    "    n = length(Y)\n",
    "\n",
    "    M = compute_M(Y,length(psi))\n",
    "    \n",
    "    # x is the phi_j-x_iTbeta\n",
    "    x =   t(matrix(rep(psi,n),m)) - matrix(rep(t(X)%*%beta,m))\n",
    "    \n",
    "    Z = M*exp(x)/(1+exp(x))\n",
    "    \n",
    "    colsums(log(rowsums(Z)))\n",
    "}\n",
    "\n",
    "#Auxiliary function to compute the M matrix defined above\n",
    "#\n",
    "# @ Param: Y, the observed Y values\n",
    "# @ Param: m, the number of possible Y values\n",
    "#\n",
    "# @ Returns: The ~M matrix defined above\n",
    "#\n",
    "\n",
    "compute_M = function (Y,m){\n",
    "    \n",
    "    #This is just a One Hot encoder:\n",
    "    \n",
    "    n = length(Y)\n",
    "    #This creates an nxm matrix whose columns\n",
    "    #are 1...1, 2...2, ...\n",
    "    M1 = t(matrix(rep(c(1:m),n),m))\n",
    "    \n",
    "    #This creates an nxm matrix whose columns\n",
    "    #are all Y (m times the same column, Y)\n",
    "    M2 = matrix(rep(c(Y),m),n)\n",
    "    \n",
    "    #We compare if they are equal, which gives\n",
    "    #the One Hot encoder\n",
    "    M = (M1==M2)+0\n",
    "    \n",
    "    #Create the matrix K\n",
    "    K = diag(m+1)\n",
    "    K = K[2:m+1,]-K[1:m,]\n",
    "    K = K[1:m,1:m+1]\n",
    "    #Return the product\n",
    "    M%*%K\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) (10pt) Derive the score functions for $\\beta$ and $\\psi_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will have:\n",
    "\n",
    "$$\n",
    "L = \\sum_{i=1}^n \\log \\sum_{j=1}^4\n",
    "\\tilde M_{i,j}\n",
    "\\phi\\left(\\psi_{j} - \\sum_{k=1}^m X_{ik}\\beta_k\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "To simplify the computations, let $\\phi_{ij}=\\phi(\\psi_{j} - X_i^\\top\\beta)$, and $\\phi_{ij}'=\\phi'(\\psi_{j} - X_i^\\top\\beta)$\n",
    "\n",
    "Since deriveatives and sums commute freely, we can compute the score easily:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\beta_k} = -\n",
    "\\sum_{i=1}^n \\left (\\sum_{j=0}^4 \\tilde M_{i,j}\\phi_{i,j} \\right )^{-1}\n",
    "\\left (\\sum_{j=0}^4\n",
    "\\tilde M_{i,j}\\phi_{i,j}'\\right )  X_{ik}\n",
    "$$\n",
    "\n",
    "For the $\\phi$, we can think again of a vector $(\\psi_0,..\\psi_n)$, and write $\\psi_k$ = $\\langle \\psi, \\vec e_k \\rangle$, to use matrix notation to make the derivative, the result is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\psi_j} = -\n",
    "\\sum_{i=1}^n \\left (\\sum_{j=0}^4 \\tilde M_{i,j}\\phi_{i,j} \\right )^{-1}\n",
    "\\left (\\sum_{j=0}^4\n",
    "\\tilde M_{i,j}\\phi_{i,j}'\\right )  X_{ik}\n",
    "$$\n",
    "\n",
    "Now, it is easy to check that $\n",
    "\\left(\\sum_{j=0}^4\n",
    "\\tilde M_{i,j}\n",
    "\\frac{\\exp(\\psi_{j} - X_i^\\top\\beta)}\n",
    "     {(1 + \\exp(\\psi_{j} - X_i^\\top\\beta))^2} e_j\\right)_{i,j}\n",
    "=     \n",
    "\\tilde M_{i,j}\n",
    "\\frac{\\exp(\\psi_{j} - X_i^\\top\\beta)}\n",
    "     {(1 + \\exp(\\psi_{j} - X_i^\\top\\beta))^2} \n",
    "$ (this is only important regarding the computations). Therefore:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\psi} = \n",
    "\\sum_{i=1}^n \\left (\\sum_{j=0}^4\n",
    "\\tilde M_{i,j}\n",
    "\\frac{\\exp(\\psi_{j} - X_i^\\top\\beta)}\n",
    "     {1 + \\exp(\\psi_{j} - X_i^\\top\\beta)} \n",
    "\\right)^{-1}\n",
    "\\tilde M_{i,j}\n",
    "\\frac{\\exp(\\psi_{j} - X_i^\\top\\beta)}\n",
    "     {(1 + \\exp(\\psi_{j} - X_i^\\top\\beta))^2} \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "As before, since we will use it with this name in the code, let $W_{i,j} = \\frac{\\exp(\\psi_{j} - X_i^\\top\\beta)}\n",
    "     {(1 + \\exp(\\psi_{j} - X_i^\\top\\beta))^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we do it in R:\n",
    "\n",
    "# Function beta_score\n",
    "#\n",
    "# @ Param: Y the observed Y values (a n-vector in our case)\n",
    "# @ Param: X the observed X values (a n by m vector in our case )\n",
    "# @ Param: beta, the beta vector (m-vector in our case)\n",
    "# @ Param: psi, the four phi values we talk about above\n",
    "#          IMPORTANT: IT assumes that the last parameter (~infinity)\n",
    "#                     IS passed as a part of psi!!!\n",
    "#\n",
    "# @ Returns: The equation above\n",
    "\n",
    "beta_score = function(Y = 0,X,beta,psi, M = 0){\n",
    "    m = length(psi)+1\n",
    "    n = length(Y)\n",
    "\n",
    "    M = compute_M(Y,length(psi))\n",
    "    \n",
    "    # x is the phi_j-x_iTbeta\n",
    "    x =   t(matrix(rep(psi,n),m)) - matrix(rep(t(X)%*%beta,m))\n",
    "    \n",
    "    Z = M*exp(x)/(1+exp(x))\n",
    "    W = M*exp(x)/(1+exp(x))**2\n",
    "    \n",
    "    sum(t(x)%*%(W/Z))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Function psi_score\n",
    "#\n",
    "# @ Param: Y the observed Y values (a n-vector in our case)\n",
    "# @ Param: X the observed X values (a n by m vector in our case )\n",
    "# @ Param: beta, the beta vector (m-vector in our case)\n",
    "# @ Param: psi, the four phi values we talk about above\n",
    "#          IMPORTANT: IT assumes that the last parameter (~infinity)\n",
    "#                     IS passed as a part of psi!!!\n",
    "#\n",
    "# @ Returns: The equation above\n",
    "\n",
    "beta_score = function(Y = 0,X,beta,psi, M = 0){\n",
    "    m = length(psi)+1\n",
    "    n = length(Y)\n",
    "\n",
    "    M = compute_M(Y,length(psi))\n",
    "    \n",
    "    # x is the phi_j-x_iTbeta\n",
    "    x =   t(matrix(rep(psi,n),m)) - matrix(rep(t(X)%*%beta,m))\n",
    "    \n",
    "    Z = M*exp(x)/(1+exp(x))\n",
    "    W = M*exp(x)/(1+exp(x))**2\n",
    "    \n",
    "    (rowSums(Z)**-1)%*%W\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10pt) Using (a) and (b), calculate the maximum likelihood estimates of $\\beta$ and $\\psi_j$ and their standard errors via the `optim` function in R. Confirm your results by comparing them to outputs from the `polr` function in the `MASS` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(X>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Cross Validation for Polynomial Regression. (18 points)\n",
    "Consider the following four data generating processes:\n",
    "\n",
    "* DGP 1: $Y = -2* 1_{\\{X < -3\\}} + 2.55* 1_{\\{ X > -2\\}} - 2* 1_{\\{X>0\\}} + 4* 1_{\\{X > 2\\}} -1* 1_{\\{ X > 3\\}}+ \\epsilon$\n",
    "* DGP 2: $Y = 6 + 0.4 X - 0.36X^2 + 0.005 X^3 + \\epsilon$\n",
    "* DGP 3: $Y = 2.83 * \\sin(\\frac{\\pi}{2} \\times X) +\\epsilon $\n",
    "* DGP 4: $Y = 4 * \\sin(3 \\pi \\times X) * 1_{\\{X>0\\}}+ \\epsilon$\n",
    "\n",
    "  $X$ is drawn from the uniform distribution in [-4,4] and $\\epsilon\n",
    "  $\n",
    "  is drawn from a standard normal ($\\mu =0$, $\\sigma^2$ = 1).\n",
    "  \\begin{enumerate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DGP1 = function(X){\n",
    "    -2   *(X < -3)\n",
    "    +2.55*(X > -2)\n",
    "    -2   *(X >  0)\n",
    "    +4   *(X >  2)\n",
    "    -1   *(X >  3)}\n",
    "DGP2 = function(X){\n",
    "    6+0.4*X-0.36*X^2+0.005*X^3\n",
    "}\n",
    "\n",
    "DGP3 = function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): attempt to apply non-function\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): attempt to apply non-function\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "X[1](0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5 pts.) Write a function to estimate the generalization error of a polynomial by $k$-fold cross-validation. It should take as arguments the data, the degree of the polynomial, and the number of folds $k$. It should return the cross-validation mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n = nrow(data);\n",
    "data = data[sample(n),]\n",
    "folds = cut(seq(1,data),breaks=N,labels=FALSE)\n",
    "for(i in 1:N)\n",
    "{\n",
    "    ind = which(folds==i,arr.ind=TRUE)\n",
    "    test = yourData[ind, ]\n",
    "    train = yourData[-ind, ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
